{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31bb5352",
   "metadata": {},
   "source": [
    "# Fake News Detection\n",
    "\n",
    "This notebook demonstrates the complete pipeline for detecting fake news using NLP and machine learning.\n",
    "\n",
    "**Methods:**\n",
    "- TF-IDF vectorization for text features\n",
    "- Logistic Regression classifier\n",
    "- Support Vector Machine (SVM) classifier\n",
    "\n",
    "**Dataset:** Synthetic fake news samples (or Kaggle dataset if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d0235",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8112428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path to import from src/\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "from src.utils import prepare_texts, get_vectorizer\n",
    "from src.generate_sample_data import generate_dataset\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c716e9",
   "metadata": {},
   "source": [
    "## 2. Generate Sample Data\n",
    "\n",
    "We'll generate synthetic fake and real news samples for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset\n",
    "train_path, test_path = generate_dataset(n_samples=1000, output_path='../data/sample_data.csv', test_split=0.2)\n",
    "\n",
    "print(f\"\\nTrain data: {train_path}\")\n",
    "print(f\"Test data: {test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efc7026",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "print(f\"\\nClass distribution (train):\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a076cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "train_df['label'].value_counts().plot(kind='bar', color=['salmon', 'skyblue'])\n",
    "plt.title('Class Distribution (Training Set)')\n",
    "plt.xlabel('Label (0=Fake, 1=Real)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f45d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample fake and real news\n",
    "print(\"Sample FAKE news:\")\n",
    "print(train_df[train_df['label']==0]['text'].iloc[0])\n",
    "print(\"\\nSample REAL news:\")\n",
    "print(train_df[train_df['label']==1]['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b0290",
   "metadata": {},
   "source": [
    "## 4. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64256e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text\n",
    "train_df['text_clean'] = prepare_texts(train_df['text'])\n",
    "test_df['text_clean'] = prepare_texts(test_df['text'])\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(train_df['text'].iloc[0])\n",
    "print(\"\\nCleaned text:\")\n",
    "print(train_df['text_clean'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122784c2",
   "metadata": {},
   "source": [
    "## 5. Feature Extraction (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "vectorizer = get_vectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform\n",
    "X_train = vectorizer.fit_transform(train_df['text_clean'])\n",
    "X_test = vectorizer.transform(test_df['text_clean'])\n",
    "y_train = train_df['label']\n",
    "y_test = test_df['label']\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e120d7",
   "metadata": {},
   "source": [
    "## 6. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23846f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "print(\"Training Logistic Regression...\")\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "acc_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {acc_logreg:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg, target_names=['Fake', 'Real']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc8c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM\n",
    "print(\"Training SVM...\")\n",
    "svm = LinearSVC(max_iter=10000, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"SVM Accuracy: {acc_svm:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=['Fake', 'Real']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cfd679",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a666ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Logistic Regression\n",
    "cm_logreg = confusion_matrix(y_test, y_pred_logreg)\n",
    "sns.heatmap(cm_logreg, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'], ax=axes[0])\n",
    "axes[0].set_title(f'Logistic Regression (Acc: {acc_logreg:.3f})')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# SVM\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Greens', cbar=False,\n",
    "            xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'], ax=axes[1])\n",
    "axes[1].set_title(f'SVM (Acc: {acc_svm:.3f})')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Logistic Regression ROC\n",
    "y_proba_logreg = logreg.predict_proba(X_test)[:, 1]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_logreg)\n",
    "auc_lr = auc(fpr_lr, tpr_lr)\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.3f})', linewidth=2)\n",
    "\n",
    "# SVM ROC\n",
    "y_scores_svm = svm.decision_function(X_test)\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, y_scores_svm)\n",
    "auc_svm = auc(fpr_svm, tpr_svm)\n",
    "plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {auc_svm:.3f})', linewidth=2)\n",
    "\n",
    "# Random classifier\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random', linewidth=2)\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves Comparison', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69400aaf",
   "metadata": {},
   "source": [
    "## 8. Test Predictions on Custom Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d27a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import clean_text\n",
    "\n",
    "def predict_news(text, model, vectorizer):\n",
    "    \"\"\"Predict if a news article is fake or real.\"\"\"\n",
    "    cleaned = clean_text(text)\n",
    "    X = vectorizer.transform([cleaned])\n",
    "    prediction = model.predict(X)[0]\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        proba = model.predict_proba(X)[0]\n",
    "        confidence = proba[prediction]\n",
    "    else:\n",
    "        confidence = None\n",
    "    \n",
    "    label = 'REAL' if prediction == 1 else 'FAKE'\n",
    "    \n",
    "    return label, confidence\n",
    "\n",
    "# Test samples\n",
    "test_texts = [\n",
    "    \"Scientists at MIT announce breakthrough in renewable energy research\",\n",
    "    \"SHOCKING: Aliens discovered living among us, government admits!\",\n",
    "    \"Local council approves new infrastructure project for public transportation\",\n",
    "    \"You won't believe what this celebrity said about vaccines!\"\n",
    "]\n",
    "\n",
    "print(\"Predictions using Logistic Regression:\\n\")\n",
    "for text in test_texts:\n",
    "    label, conf = predict_news(text, logreg, vectorizer)\n",
    "    conf_str = f\" (confidence: {conf:.2%})\" if conf else \"\"\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Prediction: {label}{conf_str}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb4baa1",
   "metadata": {},
   "source": [
    "## 9. Feature Importance (Top Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b748734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names and coefficients from Logistic Regression\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefficients = logreg.coef_[0]\n",
    "\n",
    "# Top words for FAKE news (negative coefficients)\n",
    "top_fake_indices = np.argsort(coefficients)[:20]\n",
    "top_fake_words = [(feature_names[i], coefficients[i]) for i in top_fake_indices]\n",
    "\n",
    "# Top words for REAL news (positive coefficients)\n",
    "top_real_indices = np.argsort(coefficients)[-20:]\n",
    "top_real_words = [(feature_names[i], coefficients[i]) for i in top_real_indices]\n",
    "\n",
    "print(\"Top 20 words indicating FAKE news:\")\n",
    "for word, coef in top_fake_words:\n",
    "    print(f\"  {word}: {coef:.4f}\")\n",
    "\n",
    "print(\"\\nTop 20 words indicating REAL news:\")\n",
    "for word, coef in reversed(top_real_words):\n",
    "    print(f\"  {word}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56fb298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top features\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Fake news indicators\n",
    "fake_words = [w for w, c in top_fake_words]\n",
    "fake_coefs = [c for w, c in top_fake_words]\n",
    "axes[0].barh(fake_words, fake_coefs, color='salmon')\n",
    "axes[0].set_xlabel('Coefficient', fontsize=11)\n",
    "axes[0].set_title('Top 20 FAKE News Indicators', fontsize=12)\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Real news indicators\n",
    "real_words = [w for w, c in reversed(top_real_words)]\n",
    "real_coefs = [c for w, c in reversed(top_real_words)]\n",
    "axes[1].barh(real_words, real_coefs, color='skyblue')\n",
    "axes[1].set_xlabel('Coefficient', fontsize=11)\n",
    "axes[1].set_title('Top 20 REAL News Indicators', fontsize=12)\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202110fd",
   "metadata": {},
   "source": [
    "## 10. Save Model\n",
    "\n",
    "Save the best performing model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd7e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Choose best model (by accuracy)\n",
    "if acc_logreg >= acc_svm:\n",
    "    best_model = logreg\n",
    "    best_name = 'logreg'\n",
    "else:\n",
    "    best_model = svm\n",
    "    best_name = 'svm'\n",
    "\n",
    "print(f\"Best model: {best_name}\")\n",
    "\n",
    "# Save\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "joblib.dump(best_model, '../models/best_model.joblib')\n",
    "joblib.dump(vectorizer, '../models/vectorizer.joblib')\n",
    "\n",
    "print(\"Model and vectorizer saved to ../models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59684718",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Generating synthetic fake/real news data\n",
    "2. Text preprocessing and cleaning\n",
    "3. TF-IDF feature extraction\n",
    "4. Training Logistic Regression and SVM classifiers\n",
    "5. Model evaluation with confusion matrices and ROC curves\n",
    "6. Feature importance analysis\n",
    "7. Making predictions on new text\n",
    "\n",
    "**Next Steps:**\n",
    "- Try the real Kaggle dataset for better results\n",
    "- Experiment with different hyperparameters\n",
    "- Try deep learning models (LSTM, BERT)\n",
    "- Add more sophisticated text preprocessing (lemmatization, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
